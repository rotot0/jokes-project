{"nbformat":4,"nbformat_minor":4,"metadata":{"accelerator":"GPU","colab":{"name":"bert_classifier.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","version":"3.7.7"},"nbTranslate":{"displayLangs":["*"],"hotkey":"alt-t","langInMainMenu":true,"sourceLang":"en","targetLang":"fr","useGoogleTranslate":true},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"24f239c7a3b04b75a9d347ef4b9388d8":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_99e8c96b43674998a8ef97c6bea2c755","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b40362c0daf84e74b88d522e57b1f3e4","IPY_MODEL_0be997b778444c1babf571b72e1004ae"]}},"99e8c96b43674998a8ef97c6bea2c755":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b40362c0daf84e74b88d522e57b1f3e4":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","state":{"_view_name":"LabelView","style":"IPY_MODEL_20422a86edf842b09a2e8f0c17611350","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.43MB of 0.43MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_371652e7b2e446e2a756ea50d3f01412"}},"0be997b778444c1babf571b72e1004ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8d67178e10354ead94a94f5717a5fecd","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0714c91dcfa54dfba834038dda8a5af4"}},"20422a86edf842b09a2e8f0c17611350":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"371652e7b2e446e2a756ea50d3f01412":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d67178e10354ead94a94f5717a5fecd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0714c91dcfa54dfba834038dda8a5af4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"notebookId":"f49429af-2e22-4b1d-ba65-aa565bfb5e9e"},"cells":[{"cell_type":"code","source":"#!g1.1\nimport pandas as pd\nimport torch\nfrom torch import Tensor\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.init import xavier_uniform_\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\nfrom transformers import GPT2Tokenizer, GPT2ForSequenceClassification\nimport torch.optim as optim\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n# from torchtext.data import BucketIterator, TabularDataset, Iterator, Field, LabelField\n\nroot=''\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\n# device = torch.device('cpu')\nprint('Using PyTorch version:', torch.__version__, ' Device:', device)\n\ndf_train = pd.read_csv(root + 'fun/train.csv')\n# df_train.head()","metadata":{"ExecuteTime":{"end_time":"2021-01-28T16:33:05.462367Z","start_time":"2021-01-28T16:33:05.025062Z"},"colab":{"base_uri":"https://localhost:8080/","height":225},"id":"o031RfNCWTvg","executionInfo":{"status":"ok","timestamp":1622818441861,"user_tz":-180,"elapsed":1374,"user":{"displayName":"Rototo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIinsdI5VomSycfMzHhasIoctmeCGzwgltjNZMw=s64","userId":"08048770386394847418"}},"outputId":"e6c347a8-5d42-47e8-c809-7e57d641e120","cellId":"emwm59ave7k2kw7cwlq2ls","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Using PyTorch version: 1.4.0  Device: cuda\n"}],"execution_count":330},{"cell_type":"code","source":"#!g1.1\ntokenizer = GPT2Tokenizer.from_pretrained('sberbank-ai/rugpt3medium_based_on_gpt2')\ntokenizer.add_special_tokens({'unk_token': '[UNK]', 'bos_token': '[BOS]', 'eos_token': '[EOS]', 'pad_token': '[PAD]'})","metadata":{"cellId":"olpgm6otgrbj5636aq8lt","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"3"},"metadata":{}}],"execution_count":331},{"cell_type":"code","source":"#!g1.1\ndf_train = df_train.dropna()\ndf_train = df_train.reset_index(drop=True)\ninput_ids = []\nattention_masks = []\nsentences = df_train['text']\nfor sent in sentences:\n    encoded_dict = tokenizer.encode_plus(\n                        sent,                     \n                        add_special_tokens = True,\n                        max_length = 80,          \n                        pad_to_max_length = True,\n                        return_attention_mask = True,\n                        return_tensors = 'pt'\n                   )\n    input_ids.append(encoded_dict['input_ids'])\n    attention_masks.append(encoded_dict['attention_mask'])\n\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)\nlabels = torch.tensor(df_train['label'])\ntrain_dataset = TensorDataset(input_ids, attention_masks, labels)\n\nbatch_size = 64\n\n# Create the DataLoaders for our training and validation sets.\n# We'll take training samples in random order. \ntrain_dataloader = DataLoader(\n            train_dataset,  # The training samples.\n            sampler = RandomSampler(train_dataset), # Select batches randomly\n            batch_size = batch_size # Trains with this batch size.\n        )","metadata":{"cellId":"i1r7we42lpleqbfn3lrz","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"}],"execution_count":282},{"cell_type":"code","source":"#!g1.1\ndf_val = pd.read_csv('fun/test.csv')\ndf_val = df_val.dropna()\ndf_val = df_val.reset_index(drop=True)\ninput_ids = []\nattention_masks = []\nsentences = df_val['text']\nfor sent in sentences:\n    encoded_dict = tokenizer.encode_plus(\n                        sent,                     \n                        add_special_tokens = True,\n                        max_length = 80,          \n                        pad_to_max_length = True,\n                        return_attention_mask = True,\n                        return_tensors = 'pt'\n                   )\n    input_ids.append(encoded_dict['input_ids'])\n    attention_masks.append(encoded_dict['attention_mask'])\n\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)\nlabels = torch.tensor(df_val['label'])\nval_dataset = TensorDataset(input_ids, attention_masks, labels)\n\nbatch_size = 32\n\n# Create the DataLoaders for our training and validation sets.\n# We'll take training samples in random order. \nvalidation_dataloader = DataLoader(\n            val_dataset, # The validation samples.\n            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n            batch_size = batch_size # Evaluate with this batch size.\n        )","metadata":{"cellId":"2gls6o2puqwj3bjmf65oqq","trusted":true},"outputs":[],"execution_count":283},{"cell_type":"code","source":"#!g1.1\nmodel = GPT2ForSequenceClassification.from_pretrained(\n    \"sberbank-ai/rugpt3medium_based_on_gpt2\", # Use the 12-layer BERT model, with an uncased vocab.\n    num_labels = 2, # The number of output labels--2 for binary classification.\n                    # You can increase this for multi-class tasks.   \n    output_attentions = False, # Whether the model returns attentions weights.\n    output_hidden_states = False, # Whether the model returns all hidden-states.\n).to(device)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.config.pad_token_id = tokenizer.pad_token_id","metadata":{"cellId":"7rqs2npsqzt13mk5weixes","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=674.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c94df95bf8241009def67ec8e353670"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1730074771.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a4415fbea0f435ebf68406b2dc6d781"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\n"},{"output_type":"stream","name":"stderr","text":"Some weights of the model checkpoint at sberbank-ai/rugpt3medium_based_on_gpt2 were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at sberbank-ai/rugpt3medium_based_on_gpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"}],"execution_count":284},{"cell_type":"code","source":"#!g1.1\nfrom transformers import get_linear_schedule_with_warmup\nimport numpy as np\nimport time\nimport datetime\n\nepochs = 1\noptimizer = torch.optim.AdamW(model.parameters(),\n                  lr = 4e-5,\n                  eps = 1e-8\n                )\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = 500,\n                                            num_training_steps = total_steps)\n\n# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"cellId":"2pg91vemfftm41ule1i00e","trusted":true},"outputs":[],"execution_count":287},{"cell_type":"code","source":"#!g1.1\nimport wandb\n\n# 1. Start a new run\nwandb.init(project='bert-jokes')","metadata":{"cellId":"s9fj2p5g00q7jk4u0nimih","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mrototo\u001B[0m (use `wandb login --relogin` to force relogin)\n"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Tracking run with wandb version 0.10.31<br/>\n                Syncing run <strong style=\"color:#cdcd00\">ancient-lion-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/rototo/bert-jokes\" target=\"_blank\">https://wandb.ai/rototo/bert-jokes</a><br/>\n                Run page: <a href=\"https://wandb.ai/rototo/bert-jokes/runs/1ui65al2\" target=\"_blank\">https://wandb.ai/rototo/bert-jokes/runs/1ui65al2</a><br/>\n                Run data is saved locally in <code>/home/jupyter/work/resources/jokes_gpt/wandb/run-20210605_113622-1ui65al2</code><br/><br/>\n            "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<h1>Run(1ui65al2)</h1><iframe src=\"https://wandb.ai/rototo/bert-jokes/runs/1ui65al2\" style=\"border:none;width:100%;height:400px\"></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7fb807baab10>"},"metadata":{}}],"execution_count":286},{"cell_type":"code","source":"#!g1.1\nimport random\nimport numpy as np\n\nseed_val = 42\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\ntraining_stats = []\ntotal_t0 = time.time()\nstep = 0\nfor epoch_i in range(0, epochs):\n    print(\"\")\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n    t0 = time.time()\n    total_train_loss = 0\n    model.train()\n\n    for step, batch in enumerate(train_dataloader):\n\n        if step % 40 == 0 and not step == 0:\n            elapsed = format_time(time.time() - t0)\n            \n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        model.zero_grad()        \n\n        output = model(b_input_ids, \n                           token_type_ids=None, \n                           attention_mask=b_input_mask,\n                           labels=b_labels)\n        loss = output[0]\n        logits = output[1]\n\n        total_train_loss += loss.item()\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n        scheduler.step()\n        step += 1\n        wandb.log({\"train_loss\": total_train_loss / step})\n\n    avg_train_loss = total_train_loss / len(train_dataloader)            \n    \n    training_time = format_time(time.time() - t0)\n\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Training epcoh took: {:}\".format(training_time))\n        \n\n    print(\"\")\n    print(\"Running Validation...\")\n\n    t0 = time.time()\n\n    model.eval()\n    total_eval_accuracy = 0\n    total_eval_loss = 0\n    nb_eval_steps = 0\n    for batch in validation_dataloader:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        with torch.no_grad():        \n            output = model(b_input_ids, \n                           token_type_ids=None, \n                           attention_mask=b_input_mask,\n                           labels=b_labels)\n            loss = output[0]\n            logits = output[1]\n        total_eval_loss += loss.item()\n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        total_eval_accuracy += flat_accuracy(logits, label_ids)\n        \n    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n    avg_val_loss = total_eval_loss / len(validation_dataloader)\n    \n    validation_time = format_time(time.time() - t0)\n    \n    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    print(\"  Validation took: {:}\".format(validation_time))\n\n    training_stats.append(\n        {\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Valid. Loss': avg_val_loss,\n            'Valid. Accur.': avg_val_accuracy,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        }\n    )\n\nprint(\"\")\nprint(\"Training complete!\")\n\nprint(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))","metadata":{"cellId":"q1sg0z730pnckz1wi4d69j","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"\n======== Epoch 1 / 1 ========\nTraining...\n  Batch    40  of  3,929.    Elapsed: 0:00:45.\n  Batch    80  of  3,929.    Elapsed: 0:01:26.\n  Batch   120  of  3,929.    Elapsed: 0:02:07.\n  Batch   160  of  3,929.    Elapsed: 0:02:49.\n  Batch   200  of  3,929.    Elapsed: 0:03:30.\n  Batch   240  of  3,929.    Elapsed: 0:04:11.\n  Batch   280  of  3,929.    Elapsed: 0:04:52.\n  Batch   320  of  3,929.    Elapsed: 0:05:33.\n  Batch   360  of  3,929.    Elapsed: 0:06:15.\n  Batch   400  of  3,929.    Elapsed: 0:06:56.\n  Batch   440  of  3,929.    Elapsed: 0:07:37.\n  Batch   480  of  3,929.    Elapsed: 0:08:18.\n  Batch   520  of  3,929.    Elapsed: 0:09:00.\n  Batch   560  of  3,929.    Elapsed: 0:09:41.\n  Batch   600  of  3,929.    Elapsed: 0:10:22.\n  Batch   640  of  3,929.    Elapsed: 0:11:03.\n  Batch   680  of  3,929.    Elapsed: 0:11:45.\n  Batch   720  of  3,929.    Elapsed: 0:12:26.\n  Batch   760  of  3,929.    Elapsed: 0:13:07.\n  Batch   800  of  3,929.    Elapsed: 0:13:48.\n  Batch   840  of  3,929.    Elapsed: 0:14:30.\n  Batch   880  of  3,929.    Elapsed: 0:15:11.\n  Batch   920  of  3,929.    Elapsed: 0:15:52.\n  Batch   960  of  3,929.    Elapsed: 0:16:33.\n  Batch 1,000  of  3,929.    Elapsed: 0:17:15.\n  Batch 1,040  of  3,929.    Elapsed: 0:17:56.\n  Batch 1,080  of  3,929.    Elapsed: 0:18:37.\n  Batch 1,120  of  3,929.    Elapsed: 0:19:18.\n  Batch 1,160  of  3,929.    Elapsed: 0:20:00.\n  Batch 1,200  of  3,929.    Elapsed: 0:20:41.\n  Batch 1,240  of  3,929.    Elapsed: 0:21:22.\n  Batch 1,280  of  3,929.    Elapsed: 0:22:03.\n  Batch 1,320  of  3,929.    Elapsed: 0:22:45.\n  Batch 1,360  of  3,929.    Elapsed: 0:23:26.\n  Batch 1,400  of  3,929.    Elapsed: 0:24:07.\n  Batch 1,440  of  3,929.    Elapsed: 0:24:48.\n  Batch 1,480  of  3,929.    Elapsed: 0:25:30.\n  Batch 1,520  of  3,929.    Elapsed: 0:26:11.\n  Batch 1,560  of  3,929.    Elapsed: 0:26:52.\n  Batch 1,600  of  3,929.    Elapsed: 0:27:33.\n  Batch 1,640  of  3,929.    Elapsed: 0:28:15.\n  Batch 1,680  of  3,929.    Elapsed: 0:28:56.\n  Batch 1,720  of  3,929.    Elapsed: 0:29:37.\n  Batch 1,760  of  3,929.    Elapsed: 0:30:18.\n  Batch 1,800  of  3,929.    Elapsed: 0:31:00.\n  Batch 1,840  of  3,929.    Elapsed: 0:31:41.\n  Batch 1,880  of  3,929.    Elapsed: 0:32:22.\n  Batch 1,920  of  3,929.    Elapsed: 0:33:03.\n  Batch 1,960  of  3,929.    Elapsed: 0:33:45.\n  Batch 2,000  of  3,929.    Elapsed: 0:34:26.\n  Batch 2,040  of  3,929.    Elapsed: 0:35:07.\n  Batch 2,080  of  3,929.    Elapsed: 0:35:48.\n  Batch 2,120  of  3,929.    Elapsed: 0:36:30.\n  Batch 2,160  of  3,929.    Elapsed: 0:37:11.\n  Batch 2,200  of  3,929.    Elapsed: 0:37:52.\n  Batch 2,240  of  3,929.    Elapsed: 0:38:33.\n  Batch 2,280  of  3,929.    Elapsed: 0:39:15.\n  Batch 2,320  of  3,929.    Elapsed: 0:39:56.\n  Batch 2,360  of  3,929.    Elapsed: 0:40:37.\n  Batch 2,400  of  3,929.    Elapsed: 0:41:18.\n  Batch 2,440  of  3,929.    Elapsed: 0:42:00.\n  Batch 2,480  of  3,929.    Elapsed: 0:42:41.\n  Batch 2,520  of  3,929.    Elapsed: 0:43:22.\n  Batch 2,560  of  3,929.    Elapsed: 0:44:03.\n  Batch 2,600  of  3,929.    Elapsed: 0:44:45.\n  Batch 2,640  of  3,929.    Elapsed: 0:45:26.\n  Batch 2,680  of  3,929.    Elapsed: 0:46:07.\n  Batch 2,720  of  3,929.    Elapsed: 0:46:48.\n  Batch 2,760  of  3,929.    Elapsed: 0:47:30.\n  Batch 2,800  of  3,929.    Elapsed: 0:48:11.\n  Batch 2,840  of  3,929.    Elapsed: 0:48:52.\n  Batch 2,880  of  3,929.    Elapsed: 0:49:33.\n  Batch 2,920  of  3,929.    Elapsed: 0:50:15.\n  Batch 2,960  of  3,929.    Elapsed: 0:50:56.\n  Batch 3,000  of  3,929.    Elapsed: 0:51:37.\n  Batch 3,040  of  3,929.    Elapsed: 0:52:18.\n  Batch 3,080  of  3,929.    Elapsed: 0:52:59.\n  Batch 3,120  of  3,929.    Elapsed: 0:53:41.\n  Batch 3,160  of  3,929.    Elapsed: 0:54:22.\n  Batch 3,200  of  3,929.    Elapsed: 0:55:03.\n  Batch 3,240  of  3,929.    Elapsed: 0:55:44.\n  Batch 3,280  of  3,929.    Elapsed: 0:56:26.\n  Batch 3,320  of  3,929.    Elapsed: 0:57:07.\n  Batch 3,360  of  3,929.    Elapsed: 0:57:48.\n  Batch 3,400  of  3,929.    Elapsed: 0:58:29.\n  Batch 3,440  of  3,929.    Elapsed: 0:59:11.\n  Batch 3,480  of  3,929.    Elapsed: 0:59:52.\n  Batch 3,520  of  3,929.    Elapsed: 1:00:33.\n  Batch 3,560  of  3,929.    Elapsed: 1:01:14.\n  Batch 3,600  of  3,929.    Elapsed: 1:01:56.\n  Batch 3,640  of  3,929.    Elapsed: 1:02:37.\n  Batch 3,680  of  3,929.    Elapsed: 1:03:18.\n  Batch 3,720  of  3,929.    Elapsed: 1:03:59.\n  Batch 3,760  of  3,929.    Elapsed: 1:04:41.\n  Batch 3,800  of  3,929.    Elapsed: 1:05:22.\n  Batch 3,840  of  3,929.    Elapsed: 1:06:03.\n  Batch 3,880  of  3,929.    Elapsed: 1:06:44.\n  Batch 3,920  of  3,929.    Elapsed: 1:07:25.\n\n  Average training loss: 0.22\n  Training epcoh took: 1:07:34\n\nRunning Validation...\n  Accuracy: 0.94\n  Validation Loss: 0.16\n  Validation took: 0:05:18\n\nTraining complete!\nTotal training took 1:12:52 (h:mm:ss)\n"}],"execution_count":297},{"cell_type":"code","source":"#!g1.1\ndef eval_model(model, loader):\n    all_logits = []\n    all_true = []\n    model.eval()\n    total_eval_accuracy = 0\n    total_eval_loss = 0\n    nb_eval_steps = 0\n\n    # Evaluate data for one epoch\n    for batch in loader:\n\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        with torch.no_grad():        \n            output = model(b_input_ids, \n                           token_type_ids=None, \n                           attention_mask=b_input_mask,\n                           labels=b_labels)\n            loss = output[0]\n            logits = output[1]\n        total_eval_loss += loss.item()\n\n        # Move logits and labels to CPU\n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        all_logits.extend(list(logits))\n        all_true.extend(list(label_ids))\n\n        # accumulate it over all batches.\n        total_eval_accuracy += flat_accuracy(logits, label_ids)\n\n\n    # Report the final accuracy for this validation run.\n    avg_val_accuracy = total_eval_accuracy / len(loader)\n    print(\"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n    all_preds = []\n    for i in range(len(all_logits)):\n        all_preds.append(F.softmax(torch.tensor(all_logits[i]), dim=-1)[1].item())\n    return all_preds, all_true","metadata":{"cellId":"0jyiulcsae5lhiqv28a1adk","trusted":true},"outputs":[],"execution_count":332},{"cell_type":"code","source":"#!g1.1\nall_preds, all_true = eval_model(model, validation_dataloader)","metadata":{"cellId":"doun6l1xafe4xp8q5wmzyl","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy: 0.94\n"}],"execution_count":301},{"cell_type":"code","source":"#!g1.1\nfrom sklearn.metrics import classification_report\nprint(classification_report(all_true, (np.array(all_preds) > 0.5).astype(int), digits=5))","metadata":{"cellId":"rgu275u8mko23xyfy4xb9","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"              precision    recall  f1-score   support\n\n           0    0.94760   0.92423   0.93577     30897\n           1    0.92606   0.94889   0.93734     30897\n\n    accuracy                        0.93656     61794\n   macro avg    0.93683   0.93656   0.93655     61794\nweighted avg    0.93683   0.93656   0.93655     61794\n\n"}],"execution_count":302},{"cell_type":"code","source":"#!g1.1\ntorch.save(model, 'classification/gpt_fun.pt')","metadata":{"cellId":"nz6gdz0v3410tvcbsvs5bd","trusted":true},"outputs":[],"execution_count":303},{"cell_type":"code","source":"#!g1.1\ndf_gold = pd.read_csv('fun/assessed.csv')\ndf_gold = df_gold.dropna()\ndf_gold = df_gold.drop(955, axis=0)\ndf_gold = df_gold.reset_index(drop=True)\ninput_ids = []\nattention_masks = []\nsentences = df_gold['text']\nfor sent in sentences:\n    encoded_dict = tokenizer.encode_plus(\n                        sent,                     \n                        add_special_tokens = True,\n                        max_length = 80,          \n                        pad_to_max_length = True,\n                        return_attention_mask = True,\n                        return_tensors = 'pt')\n    input_ids.append(encoded_dict['input_ids'].long())\n    attention_masks.append(encoded_dict['attention_mask'])\n\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)\nlabels = torch.tensor(df_gold['label'])\ngold_dataset = TensorDataset(input_ids, attention_masks, labels)\n\nbatch_size = 16\n\n# Create the DataLoaders for our training and validation sets.\n# We'll take training samples in random order. \ngold_dataloader = DataLoader(\n            gold_dataset, # The validation samples.\n            sampler = SequentialSampler(gold_dataset), # Pull out batches sequentially.\n            batch_size = batch_size # Evaluate with this batch size.\n        )","metadata":{"cellId":"d4vbupi1ljqdiyy6gkkenr","trusted":true},"outputs":[],"execution_count":343},{"cell_type":"code","source":"#!g1.1\nfrom sklearn.metrics import classification_report\nmodel = torch.load('classification/gpt_fun.pt')\nall_preds, all_true = eval(model, gold_dataloader)\nprint(classification_report(all_true, (np.array(all_preds) > 0.5).astype(int), digits=5))","metadata":{"cellId":"aks5qvnc82vrg9pjx6c8w","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy: 0.90\n              precision    recall  f1-score   support\n\n           0    0.93231   0.87410   0.90227       977\n           1    0.87187   0.93103   0.90048       899\n\n    accuracy                        0.90139      1876\n   macro avg    0.90209   0.90257   0.90138      1876\nweighted avg    0.90335   0.90139   0.90141      1876\n\n"}],"execution_count":344},{"cell_type":"code","source":"#!g1.1\nall_preds, all_true = eval(model2, gold_dataloader)\nprint(classification_report(all_true, (np.array(all_preds) > 0.5).astype(int), digits=5))","metadata":{"cellId":"6kv6v97qxnt1elpxsr53s5","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Error in callback <function _WandbInit._resume_backend at 0x7fb807901ef0> (for pre_run_cell):\nAccuracy: 0.52\n              precision    recall  f1-score   support\n\n           0    0.56555   0.15623   0.24483     30897\n           1    0.51051   0.87999   0.64616     30897\n\n    accuracy                        0.51811     61794\n   macro avg    0.53803   0.51811   0.44549     61794\nweighted avg    0.53803   0.51811   0.44549     61794\n\nError in callback <function _WandbInit._pause_backend at 0x7fb807c4a710> (for post_run_cell):\n"}],"execution_count":312},{"cell_type":"code","source":"#!g1.1\n","metadata":{"cellId":"anbkeugahupt4g23uxi16h"},"outputs":[],"execution_count":null}]}